{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational phospho-proteomic network inference pipeline\n",
    " \n",
    "\n",
    "##### The script cells below were used to analyze wild type and mutant phosphoproteomic data as submitted in MacGilvray et al. (Network inference reveals novel connections in pathways regulating growth and defense in the yeast salt response. Matthew E. MacGilvray+, Evgenia Shishkova+, Deborah Chasman, Michael Place, Anthony Gitter, Joshua J. Coon, Audrey P. Gasch. bioRxiv 2017. doi:10.1101/176230).  The pipeline takes a list of phospho-peptides from S. cerevisiae and defines groups of likely co-regulated peptides that share the same phosphorylation motif (see manuscript Methods for details).  For each of these ‘modules’ of peptides, the pipeline then identifies ‘shared interactors’, defined as proteins from a background network of protein interactions that show more physical interactions with module constituent proteins then expected by chance.  Shared interactor-module pairs serve as inputs for a previously developed Integer Programming (IP) approach that connects the sources to their downstream target submodules (Chasman et al., 2014).\n",
    "\n",
    "##### Please see our bioRxiv preprint for additional information:\n",
    "#### _Network inference reveals novel connections in pathways regulating growth and defense in the yeast salt response._ Matthew E. MacGilvray+, Evgenia Shishkova+, Deborah Chasman, Michael Place, Anthony Gitter, Joshua J. Coon, Audrey P. Gasch. bioRxiv 2017. doi:10.1101/176230\n",
    "\n",
    "\n",
    "##### The user should define differentially changing phospho-peptides in the \"WT\" or \"Parent\" strain using their own criteria (eg; fold-change, p-value, etc.), followed by grouping/clustering phospho-peptides based on similar directionality of abundance change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files required ( Provided in the Git Repository )\n",
    "\n",
    "** Link or Copy reference/, required/ and Mok_kinase_PWMs/ directories into your working directory.**\n",
    "\n",
    "1.  reference/orf_trans_all.20150113.fasta    \n",
    "2.  reference/bgNtWk.csv\n",
    "3.  reference/Background_Network.csv\n",
    "4.  Mok_kinase_PWMs/Mok_Kinase_PWM_*.csv\n",
    "5.  required/Kinase_Groups.csv\n",
    "11. required/kinase_phosphatase_yeast.csv\n",
    "\n",
    "## User supplied files\n",
    "1. idModules file, for Identity Modules and Submodules step.\n",
    "2. Submodules.txt, user may provide if Identify Modules and Submodules step is skipped.\n",
    "\n",
    "## Output files\n",
    "\n",
    "1. Motif-x -- single file and 3 directories which contain LOGO png's and original Motif-x result webpage.\n",
    "2. Submodules.txt \n",
    "3. Shared_interactors.csv -- list of all shared interactors w/ p-value and p-adjust values.\n",
    "4. position_weight_matrix.txt -- use w/ Kullback-Leibler script.\n",
    "5. 2 directories for the Kullback-Leibler (unshuffled, shuffled)\n",
    "6. Shared_interactors_Kinase_FDR.csv -- Kullback-Leibler kinase submodules w/ FDR score.\n",
    "7. Network.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify motifs\n",
    "    \n",
    "    This automates submitting jobs to the Motif-x Website (http://motif-x.med.harvard.edu/)\n",
    "    \n",
    "### Input  : single text file (called inputfiles in next cell) listing text (csv) files to process, one file name per line.\n",
    "\n",
    "    text file:\n",
    "    data_sheet1.csv\n",
    "    data_sheet2.csv\n",
    "\n",
    "\tfile format, comma separated:\n",
    "\n",
    "|       Ppep        |       Group      |     Localized_Sequence    |    Motif_X_Input_Peptide   |\n",
    "|:-----------------:|:----------------:|:-------------------------:|:--------------------------:|\n",
    "|   YAL035W_T388    |      Induced     |     AAEKILtPEsQLKK        |    AAEKILT*PES*QLKK    |\n",
    "\n",
    "\n",
    "\tColumn order is unimportant, column names must match above.\n",
    "    \n",
    "### Output:\n",
    "A text table named after the input file containing all the motifs matched to a gene.<br>\n",
    "        \n",
    "Given an input file named,  motifx_sample.xlsx the final results file will be:<br>\n",
    "    \n",
    " > motifx_sample-Motifx-results.txt\n",
    "         \n",
    "The rest of the results are in a directory.  For instance if your input file is called\n",
    "motifx_sample.xlsx, 3 directories will be created one for each central character.  These \n",
    "contain the LOGO pngs and the original html results page.<br>         \n",
    " > motifx_sample_T<br>\n",
    " > motifx_sample_S<br>\n",
    " > motifx_sample_Y<br>\n",
    " \n",
    " \n",
    " ## Enter current working directory in next cell, which must be run to load python libraries and set the working directory.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# required python libraries\n",
    "import Bio\n",
    "import bisect\n",
    "import errno\n",
    "import glob\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from scipy.stats import hypergeom\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "from Bio.Alphabet import IUPAC\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import yeast_Gene_name_to_ORF                 # for SGD Systematic Name to look-up Standard Name\n",
    "\n",
    "stats = importr('stats')                      # for Benjamini Hochberg procedure\n",
    "\n",
    "# ENTER WORKING DIRECTORY \n",
    "current_dir = '/home/mplace/projects/forMatt/Phospho_Network/forPaper'\n",
    "os.chdir(current_dir)\n",
    "print('Working in directory: %s' % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'Motifx.py' -f 'inputfiles' -u 'reference/orf_trans_all.20150113.fasta'\n",
    "\n",
    "### WHEN COMPLETE SEE WORKING DIRECTORY FOR YOUR MOTIF-X RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Modules and Submodules step.\n",
    "\n",
    "This script identifies co-regulated groups of phospho-peptides using the following approach:\n",
    "\n",
    "1) Identifies 'modules', which are groups of phospho-peptides that exhibit the same directionality in stress-dependent abundance change (ie, increased 'Induced', or decreased 'Repressed') and the same motif. The module nomenclature is as follows: Induced/Repressed- motif (ex: Induced..RK.s....).\n",
    "\n",
    "2)  Partitions modules into 'submodules' based on their phospho-peptide constituents dependency on a protein(s) for stress-dependent abundance changes (ie, phospho-peptides that exhibit increased 'amplified' or decreased 'defective' abundance in a deletion strain compared to the 'WT' or 'Parental' type strain). These phenotypes are user defined. If two or more mutant phenotypes are recorded for a phospho-peptide then it's placed into two separate subModules (one for each mutant phenotype). If there was not a mutant phenotype at a user defined threshold then the phenotype is 'No-Phenotype'\n",
    "\n",
    "The submodule nomenclature is as follows: module name-mutant phenotype/No-Phenotype (ex: Induced..RK.s....Mutant_Defective).\n",
    "\n",
    "Possible submodule phenotypes: Induced-Defective, Induced-Amplified, Repressed-Defective, Repressed-Amplified, Induced-No-Phenotype, Repressed-No-Phenotype\n",
    "\n",
    "\n",
    "### The motifx results need to be classified by the user.  Example output from the motifx :\n",
    "|           Ppep            |   Cluster      |     Motifx         |        Peptide     |\n",
    "|:-------------------------:|:--------------:|:------------------:|:------------------:|\n",
    "|       YAL035W_T388        |      Name      |   ......TP.....    |     AATPAATPTPSSA  |\n",
    "\n",
    "\n",
    "### The user must add the grouping. Here is an example of the idModules.csv file used in the next step. \n",
    "|         Ppep          |     Cluster     |         Motif         |     Peptide    |   Mutant1   | Mutant2  |\n",
    "|:---------------------:|:---------------:|:---------------------:|:--------------:|:-----------:|:--------:|\n",
    "|     YAL035W_T388      |     Induced     |     ......SP.....     |  NKKNEASPNTDAK |   Induced   | Repressed|\n",
    "\n",
    "\n",
    "\n",
    "1. Mutant1 and Mutant2 correspond to gene names \n",
    "2. Induced,Repressed are groupings provided by user.\n",
    "\n",
    "The resulting output file will have Submodules identified at the protein level.\n",
    "\n",
    "### Skip to Identify Shared Interactors step if you already have  a \"Submodule, orf\"  file and no mutant strain data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter in Identify Modules & Submodules file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT FILE NAME \n",
    "inputData = 'idModules.csv'\n",
    "\n",
    "\n",
    "# identifies 'modules', which are groups of phospho-peptides \n",
    "modData = set() # hold a unique list of Submodule,ORF data\n",
    "ct      = 4     # position holder for input data list, after this position the mutant strain names begin\n",
    "                # for example: \"Ppep,Cluster,Motif,Peptide,gene1,gene2\", gene1 & gene2 are used as strain names  \n",
    "\n",
    "# open file to create Submodule,ORF list\n",
    "with open(inputData) as file:\n",
    "    columns = file.readline().rstrip().rsplit(',')    # grab header, ex. \"Ppep,Cluster,Motif,Peptide,ire1,mkk1_2\"\n",
    "                                             # all columns after Peptide, are considered mutant strain names\n",
    "    numStrains = len(columns[ct:])           # count number of mutant strains, all items after Peptide in header\n",
    "    \n",
    "    for line in file:\n",
    "        row  = line.rstrip().split(',')     \n",
    "        gene = row[0].split('_')[0]              # Get gene name from first column, YGR240C_S895 becomes YGR240C\n",
    "        if row[2] == '':                         # skip rows w/ no motif\n",
    "            continue\n",
    "            \n",
    "        countBlanks = row[ct:].count('')         # count number of missing mutant phenotypes \n",
    "        if countBlanks < numStrains:             # if at least one phenotype\n",
    "            for idx, val in enumerate(row[ct:]): # loop through each phenotype\n",
    "                name = row[0].split('_')[0]      # get gene name\n",
    "                if val == '':                    # if phenotype is missing skip it\n",
    "                    continue\n",
    "                else:\n",
    "                    subModule = row[1] + '_' + row[2]  + '_' + columns[ct + idx] + '_' + val + ',' + name + '\\n'\n",
    "                    modData.add(subModule)\n",
    "        else: # here we have a motif but no strain phenotype\n",
    "            name = row[0].split('_')[0]\n",
    "            subModule = row[1] + '_' + row[2]  + '_' + 'No_Phenotype_Exists' + ',' + name + '\\n'\n",
    "            modData.add(subModule)\n",
    "\n",
    "# Items in list should be unique\n",
    "# write the Submodule constituent file\n",
    "with open('Submodules.txt', 'w') as out:\n",
    "    out.write('Submodule,ORF\\n')\n",
    "    for sb in modData:\n",
    "        out.write(sb)\n",
    "print('ID submodules Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Shared Interactors \n",
    "\n",
    "Identify proteins enriched for interactions with Submodule constituent proteins, based on known interactions in the background network. We call these proteins 'Shared Interactors'. The background network is a protein interaction network curated in yeast under mostly nutrient replete conditions that contains 4638 proteins and ~ 25,000 interactions, including directed (ex; kinase-substrate), and non-directed interactions. \n",
    "\n",
    "Proteins enriched for interactions with Submodule proteins at a 5% FDR, determined by a hypergeometric test and BH correction, are considered shared interactors.\n",
    "\n",
    "Shared Interactors represent numerous functional classes, including kinases and phosphatases. Kinase and phosphatase shared interactors represent potential Submodule regulators.\n",
    " \n",
    "HyperG function:\n",
    "distrib=hypergeom(N,M,n)\n",
    "distrib.pmf(m)\n",
    "\n",
    "* N - population size (4638 unique proteins in Background network file - phospho_v4_bgnet_siflike_withdirections_Matt_Modified.csv)\n",
    "\n",
    "* M - total number of successes in population  (# of interactions for a given protein. ie. Protein A has 200 known interactions in the background network).\n",
    "\n",
    "* n - the number of trials (sample size) -  ie. (Number of proteins that reside within a submdoule)\n",
    "\n",
    "* m - the number of successes - i.e. Protein A, a shared interactor, has 35 interactions with proteins in Submodule B. \n",
    " \n",
    "The resulting shared interactor p-values are scored for significance using Benjamini-Hochberg proceedure.\n",
    "See the original paper for more information.\n",
    "\n",
    "__Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing__<br>\n",
    "Yoav Benjamini and Yosef Hochberg<br>\n",
    "Journal of the Royal Statistical Society. Series B (Methodological)<br>\n",
    "Vol. 57, No. 1 (1995), pp. 289-300<br>\n",
    "\n",
    "\n",
    "A file containing all shared interactors ( __Shared_interactors.csv__) can be found in current working directory.<br> \n",
    "Columns:\n",
    "\n",
    "    Submodule         - Name, i.e. Induced_......SP....._mkk1_2_Induced_Defective<br>\n",
    "    Shared_Interactor - Protein name, i.e. YBL079W\n",
    "    n                 - Sample size, hyperGeometric test<br> \n",
    "    N                 - Population size, hyperGeometric test<br>\n",
    "    M                 - Number of successes in Population, hyperGeometric test<br>\n",
    "    m                 - Number of successes, hyperGeometric test<br>\n",
    "    p-value           - hyperGeometric p-value<br>\n",
    "    Interaction       - interaction type<br>\n",
    "    Direction         - input, output, none<br>\n",
    "    Standard_name     - nup170 for the above example of YBL079W<br>\n",
    "    (i/n)*Q\t       - value returned by BH test<br>\n",
    "    significance      - 1 = significant, 0 = not significant<br>\n",
    "\n",
    "\n",
    "## The shared_interactors.csv is not filtered for BH significance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the background network into data structure\n",
    "bgNtwk = 'reference/bgNtWk.csv'\n",
    "\n",
    "# load background network w/ directionality\n",
    "bgNtwk_directions = 'reference/Background_Network.csv'\n",
    "\n",
    "# Population Size for Hypergeometric test\n",
    "# Change if required\n",
    "N = 4638                \n",
    "\n",
    "# Significance test cutoff value Q\n",
    "Q = 0.05\n",
    "\n",
    "# CHANGE OUTPUT FILE NAME HERE IF DESIRED\n",
    "outFile = open('Shared_interactors.csv', 'w')\n",
    "\n",
    "# use dictionary of sets, key = Protein name i.e. YGL120C  value = set of all genes and interaction type \n",
    "# Interaction type is not stored, it looks like :\n",
    "# ntwk['YDR174W'] = {('YNL135C', 'ppi'), ('YPR104C', 'ppi'), ('YER148W', 'ppi'), ('YGR274C', 'ppi'),\n",
    "# ('YDR174W', 'ppi'), ('YJL074C', 'ppi'), ('YML015C', 'ppi'), ('YDR510W', 'ppi')}\n",
    "ntwk = {}\n",
    "\n",
    "with open(bgNtwk, 'r') as file:\n",
    "    file.readline()                                     # skip header\n",
    "    for line in file:\n",
    "        dat = line.rstrip().split(',')                  # line looks like: YGR240C,YJL039C,ppi,0\n",
    "        if dat[0] not in ntwk:                          # check 1st protein & add 2nd protein to set\n",
    "            ntwk[dat[0]] = {}\n",
    "            ntwk[dat[0]][dat[1]] = dat[2]\n",
    "        else:\n",
    "            ntwk[dat[0]][dat[1]] = dat[2]\n",
    "        \n",
    "        if dat[1] not in ntwk:                          # check 2nd protein & add 1st protein to set\n",
    "            ntwk[dat[1]] = {}\n",
    "            ntwk[dat[1]][dat[0]] = dat[2]\n",
    "        else:\n",
    "            ntwk[dat[1]][dat[0]] = dat[2]\n",
    "            \n",
    "file.close()\n",
    "\n",
    "direction = {}                     # key = YJL187C_YDR054C value = ['kinase_substrate', 'ubiquitination:Reversed']\n",
    "with open(bgNtwk_directions, 'r') as f:\n",
    "    f.readline()                                         # skip header\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        interaction = dat[0] + '_' + dat[1]              # join protein names to make key\n",
    "        if interaction not in direction:\n",
    "            direction[interaction] = []\n",
    "            direction[interaction].append(dat[2])        # add interaction\n",
    "        else:\n",
    "            direction[interaction].append(dat[2])            \n",
    "f.close()\n",
    "\n",
    "# Submodule constituent information is in modData from previous step\n",
    "# collect the Genes & counts for proteins in a submodule \n",
    "# an example submodule looks like: Repressed_...R..S......_ire1_Repressed_Defective\n",
    "motifCt = {}  #key = submodule, value = a dict w/ 'count' = num of motif, 'proteins' = proteins in submodule group \n",
    "\n",
    "for i in modData:\n",
    "    dat = i.split('_')                    \n",
    "    gene = dat[-1].rstrip().split(',')[1] # split to get gene name\n",
    "    sbMds = i.rstrip().split(',')         # get submodule name \"Induced_...K..SP....._ire1_Induced_Amplified\"\n",
    "    if sbMds[0] not in motifCt:           # add submodule name if not in dict\n",
    "        motifCt[sbMds[0]] = {}\n",
    "        motifCt[sbMds[0]]['count'] = 1    # this is \"n\" for hypergeometric test, example:  ...K..SP.....\n",
    "        motifCt[sbMds[0]]['proteins'] = []\n",
    "        motifCt[sbMds[0]]['proteins'].append(gene)\n",
    "    else:                                  \n",
    "        motifCt[sbMds[0]]['count'] += 1              # count the number of submodules \n",
    "        motifCt[sbMds[0]]['proteins'].append(gene)   # gene name which participates in submodule\n",
    "        \n",
    "# now get the background protein interactors for each ORF/GENE in each submodule group\n",
    "# For instance \n",
    "# groupd :  Repressed_......TP....._mkk1_2_Repressed_Defective, has 2 ORFs in the group: YGR202C,YLR190W\n",
    "# take each one and find the background protein interactors\n",
    "# print submodule information\n",
    "# example:\n",
    "# Induced_...R..S......_mkk1_2_Induced_Defective 11\n",
    "# YNL183C,YGL049C,YDL022W,YBL058W,YHR097C,YOR220W,YPL085W,YFL007W,YDR135C,YOL087C,YJR005W  \n",
    "\n",
    "outFile.write( 'Submodule,Shared_Interactor,n,N,M,m,p-value,Interaction,Direction,Standard_name,(i/n)*Q,significance\\n')   # write file header\n",
    "\n",
    "testList  = []                                                      # list of lists , holds pvalue results\n",
    "sigPValue = {}                                                      # store p-value for significance test\n",
    "sigScore  = {}                                                      # significance dict used to implement \n",
    "                                                                    # threshold cutoff (i/m)*Q < p-value\n",
    "                                                                    # key = SubModule + Gene Name ,value = significance Score\n",
    "        \n",
    "# loop through all items in motifCt[submodule] items\n",
    "for subMod, val in motifCt.items():\n",
    "    n           = motifCt[subMod]['count']                           # number of submodule members\n",
    "    match       = set()                                              # list of interacting proteins w/ in a submodule\n",
    "    count_m     = {}                                                 # count the occurances for all proteins in subMod\n",
    "    interaction = {}                                                 # dict of sets stores interaction type for Shared Interactor\n",
    "    for prot1, prot2 in itertools.combinations(val['proteins'],2):   # this should do all against all comparisons\n",
    "        if prot1 in ntwk and prot2 in ntwk:          \n",
    "            proteins = ntwk[prot1].keys() & ntwk[prot2].keys()       # perform set like intersection operation\n",
    "        if proteins:  \n",
    "            for p in proteins:                                       # make a unique count of proteins\n",
    "                match.add(p)\n",
    "                if prot1 not in count_m:\n",
    "                    count_m[prot1] = set()\n",
    "                    count_m[prot1].add(p)\n",
    "                else:\n",
    "                    count_m[prot1].add(p)\n",
    "                # Find the interaction types for a subModule protein and it's constituents\n",
    "                # the dict of sets stores the unique interaction types for each constituent\n",
    "                if prot1+'_'+p in direction:                         # if 1st protein_consituent has a direction\n",
    "                    if p not in interaction:\n",
    "                        interaction[p] = set()\n",
    "                        interaction[p].add(''.join(direction[prot1+'_'+p]))\n",
    "                    else:\n",
    "                        interaction[p].add(''.join(direction[prot1+'_'+p]))\n",
    "\n",
    "                if prot2+'_'+p in direction:                         # 2nd protein_constituent \n",
    "                    if p not in interaction:\n",
    "                        interaction[p] = set()\n",
    "                        interaction[p].add(''.join(direction[prot2+'_'+p]))\n",
    "                    else:\n",
    "                        interaction[p].add(''.join(direction[prot2+'_'+p]))\n",
    "                                      \n",
    "    for i in match:\n",
    "        # find interaction type\n",
    "        if len(interaction[i]) > 1:                                     # multiple interaction types\n",
    "            iType = 'None'\n",
    "        else:\n",
    "            iType = ' '.join(interaction[i])                            #  one interaction\n",
    "            \n",
    "        if 'Reversed' in iType:                                         # Classify input/output direction\n",
    "            directionality = 'output'\n",
    "        elif iType == 'None':                                           # multiple interaction types\n",
    "            directionality = 'None'\n",
    "        else:\n",
    "            directionality = 'input'                                    # ppi, kinase_substrate, \n",
    "        \n",
    "        m = 0                                                           # total number of SI w/in a submodule group\n",
    "        M = len(ntwk[i])                                                # Number of genes in background network\n",
    "        for k in count_m.keys():                                        # count the number of SI\n",
    "            if i in count_m[k]:\n",
    "                m += 1\n",
    "        pvalue = hypergeom.sf(m-1,N,M,n)                                # call hypergeometric test\n",
    "        testList.append([subMod,i,str(n),str(N),str(M), str(m), str(pvalue), iType, directionality])\n",
    "        if subMod + '_' + i not in sigPValue:\n",
    "            sigPValue[subMod + '_' + i] = pvalue\n",
    "        else:\n",
    "            print('Duplicates in sigPValue')\n",
    "            \n",
    "    match = set()\n",
    "\n",
    "# Significance test procedure   (p-value(rank)/numTests) * Q, Q = 0.5 cutoff by default         \n",
    "numTests = len(sigPValue)          \n",
    "rank     = 1.0                                                 # rank value\n",
    "maxRank  = 0                                                   # max rank position for the BH cutoff\n",
    "idx      = 0\n",
    "for k in sorted(sigPValue, key=lambda k: sigPValue[k]):        # sorts sigPValue by value returning the keys \n",
    "    test = (rank/numTests) * Q  \n",
    "    rank += 1.0                         \n",
    "    sigScore[k] = test\n",
    "    \n",
    "    # if p-value is less than (i/numTest)*Q set record position, used later to report BH significance\n",
    "    if float(sigPValue[k]) < test:\n",
    "        maxRank = idx\n",
    "    idx += 1\n",
    "\n",
    "# get a set of the names where BH score is significant\n",
    "count   = 0\n",
    "rankSet = set()\n",
    "for k in sorted(sigPValue, key=lambda k: sigPValue[k]):\n",
    "    if count <= maxRank:\n",
    "        rankSet.add(k)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "for i in testList:                                   # write results to file\n",
    "    tmpName = i[1]                                   # for some reason the bgntwk has all of the dashes removed\n",
    "    oldName = list(i[1])                             # here we put them back for name look-up  \n",
    "    sigLookup = i[0] + '_' + tmpName                 # for sig dict value lookup\n",
    "    \n",
    "    if oldName[-1] in ['A','B','D']:\n",
    "        endChar = oldName.pop()\n",
    "        nwName  = ''.join(oldName) + '-' + endChar\n",
    "    elif tmpName.endswith('CC'):\n",
    "        endChar = oldName.pop()\n",
    "        nwName  = ''.join(oldName) + '-' + endChar \n",
    "    elif tmpName.endswith('WC'):\n",
    "        endChar = oldName.pop()\n",
    "        nwName  = ''.join(oldName) + '-' + endChar        \n",
    "    else:\n",
    "        nwName = i[1]       \n",
    "    \n",
    "    if sigLookup in rankSet:\n",
    "        significance = '1'\n",
    "    else:\n",
    "        significance = '0'\n",
    "        \n",
    "    outFile.write('%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n'  %(i[0], i[1], i[2], i[3], i[4],\\\n",
    "                                                       i[5], i[6], i[7], i[8], yeast_Gene_name_to_ORF.sc_orfToGene[nwName],\\\n",
    "                                                       str(sigScore[sigLookup]),significance ) )\n",
    "\n",
    "outFile.close()\n",
    "print('Identify Shared Interactors Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Kullback-Leibler Script\n",
    "\n",
    "**input:** idModules.csv file is parsed to produce a individual fasta files for each Module as shown:\n",
    "\n",
    "| Module | Name | Sequence |\n",
    "|:------:|:----:|:--------:|\n",
    "|Induced_......SP.....|YJL082W_S187|KNSSSPSPSEKSQ|\n",
    "\n",
    "All peptide sequences should be the same length (13 amino acids).\n",
    "\n",
    "Module constituents will used here, not submodules. \n",
    "Fasta Files are placed in a directory called: **fasta/**\n",
    "\n",
    "The output Fasta format files are named with their module designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasta = {}                                                   # dictionary, key = Module, value is \">Name\\nSequence\"\n",
    "\n",
    "with open(inputData, 'r') as f:                              # open idModules.csv file\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        if dat[3] == '':                                     # if sequence missing skip\n",
    "            continue\n",
    "        name = dat[1] + '_' + dat[2]                         # create Module name to use as key \n",
    "        if name not in fasta:\n",
    "            fasta[name] = []\n",
    "            fasta[name].append('>' + dat[0] + '\\n' + dat[3] + '\\n') # Name plus Sequence\n",
    "        else:\n",
    "            fasta[name].append('>' + dat[0] + '\\n' + dat[3] + '\\n')\n",
    "f.close()\n",
    "\n",
    "# if fasta directory does not exist, create it.\n",
    "if not os.path.exists( current_dir + '/fasta'):\n",
    "    try:\n",
    "        os.makedirs('fasta')\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# write individual fasta files\n",
    "for k,v in fasta.items():\n",
    "    with open('fasta/' + k + '.fasta', 'w') as out:\n",
    "        for i in v:\n",
    "            out.write(i)\n",
    "\n",
    "# Remove duplicate sequences from each fasta file\n",
    "for fasta in glob.glob('fasta/*'):\n",
    "    clean = {}\n",
    "    for seq_record in SeqIO.parse(fasta, 'fasta'):           # create Seq objects\n",
    "        s = str(seq_record.seq)\n",
    "        if s not in clean:\n",
    "            clean[s] = seq_record                            # only keep unique sequences\n",
    "            \n",
    "    out_handle = open('tmp.fasta', 'w')              \n",
    "    \n",
    "    for k,v in clean.items():                                # write unique sequences to tmp file  \n",
    "        SeqIO.write(v, out_handle, 'fasta')\n",
    "    out_handle.close()\n",
    "            \n",
    "    shutil.move('tmp.fasta', fasta)                          # overwrite original fasta file    \n",
    "\n",
    "# OUTPUT: fasta/*.fasta \n",
    "\n",
    "alphabet = IUPAC.protein                                     # use protein alphabet\n",
    "instances = []\n",
    "# list of amino acids used to print the position weight matrix\n",
    "AminoList = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y' ]\n",
    "# column numbers for printing pwm, length of peptide, assumed to be 13, if different change last value\n",
    "pep_Header = ','.join([str(i) for i in range(0,13)])     \n",
    "\n",
    "# creates Position weight matrix includes all Modules \n",
    "instances = []\n",
    "with open('position_weight_matrix.txt', 'w') as out:\n",
    "    out.write('Motif,AA,%s\\n' %(pep_Header))                   \n",
    "    for x in os.listdir('fasta/'):                            # process all fasta files in the directory\n",
    "        if x.endswith('.fasta'):\n",
    "            with open('fasta/' + x, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('>'):                                       \n",
    "                        continue\n",
    "                    line = line.rstrip()                                                 \n",
    "                    instances.append(Seq(line, IUPAC.protein))# add amino acid sequence to instances\n",
    "                m = motifs.create(instances)\n",
    "                pwm = m.counts.normalize(pseudocounts = 1)    # Add a +1 pseudocount\n",
    "                instances = []\n",
    "                name = re.sub('.fasta', '', x)                # use file name for 1st column          \n",
    "                for aa in AminoList :\n",
    "                    score = [ str(i) for i in pwm[aa]]\n",
    "                    score = ','.join(score)\n",
    "                    out.write('%s,%s:,%s\\n' %(name,aa,score))\n",
    "out.close()                   \n",
    "# OUTPUT: position_weight_matrix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Kullback-Leibler Module to Each Kinase\n",
    "\n",
    "To quantify similarity between the Mok et. al. kinase PWMs and the module PWMs. Script employs a previously described quantitative motif comparison method called Kullback-Leibler divergence (KLD) (Thijs et al., 2002, Gupta et al., 2007). KLD generates a similarity measure by comparing the Kullback-Leiber distance, or information content, for each amino acid at each position between a query and comparison PWM. The more alike two PWMs are, the closer to zero the score approaches.\n",
    "\n",
    "** KLD(X,Y) = 1/2 (E Xalog(Xa/Ya) + E Yalog(Ya/Xa))**\n",
    "Where ‘X’ represents a query PWM position and ‘Y’ a comparison PWM position. Xa indicates the probability of a given amino acid a ε A in X. The symbol ‘A’ represents the length of the motif alphabet, which is 20, representing each of the naturally occurring amino acids.\n",
    "\n",
    "**Input:** A plain text .csv file that contains all module position weight matrices. Each module PWM should have 20 rows, representing each of the 20 naturally occurring amino acids. They are in a column called \"AA\" which stands for amino acid. There should also be 13 columns, labeled 0-12 (representing the 13 amino acid sequence length of the phospho-peptides used to build the position weight matrix) that contain the frequency of each amino acid at each position.\n",
    "\n",
    "Csv file format Motif,AA,0,1,2,3,4,5,6,7,8,9,10,11,12 Induced_...sP.,P:,0.05,0.05,0.03, 0.05,0.05,0.03,0.05,0.05,0.03, 0.05,0.05,0.03\n",
    "\n",
    "** A directory that contains the Mok et al kinase PWMs is required.** They have the identical format as above. They have been pre-generated and are available for download on Github. The directory is titled, \"Mok_kinase_PWMs\" \n",
    "Please specify the full path to the Mok directory.\n",
    "\n",
    "Kullback-Leibler is run using:  Shuffle-kullback-Leibler.py\n",
    "\n",
    "#### usage: kullback-Leibler.py -f  Position_weight_matrix.csv\n",
    "\n",
    "** Shuffle kullback-Leibler results for use w/ FDR function.**\n",
    "\n",
    "\n",
    "** optional arguments: <br>\n",
    "  -h, --help          show this help message and exit <br>\n",
    "  -f , --file         position_weight_matrix.txt file <br>\n",
    "  -m , --mokdir       Full path to Mok_kinase_PWMs directory <br>\n",
    "  -i , --iterations   Total number of iterations, this will be divided by number of processes.<br>\n",
    "  -o , --out          Output directory <br>\n",
    "  -p , --processes    Number of processes to run, be smart don't use more than you have!**<br>\n",
    "\n",
    "** Kullback-Leibler is first run w/ just a single iteration (default) this will not shuffle the data.**<br>\n",
    "** Input data will be shuffled for any number of iterations greater than 1 **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run KL test on original data, output is put in 'Kullback-Leibler' directory, unless you change it.\n",
    "%run -i '../kullback-Leibler.py' -f 'position_weight_matrix.txt' -m '/home/mplace/projects/forMatt/Phospho_Network/forPaper/Mok_kinase_PWMs/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler Module to Each Kinase Shuffled 1000x\n",
    "\n",
    "Purpose:  The same algorithm as the last step is used but w/ 1000 Shuffles of the Mok Kinase PWMs are performed by the script, generating randomized PWMs that are compared against the Module PWMs, producing a distribution of scores.\n",
    "\n",
    "Output: A directory containing plain text .csv files named after each module. Within\n",
    "the .csv files are 63,000 KLD scores representing how well the 63 Mok et al kinases\n",
    "match the module motif after 1000 permutations of each Mok kinase.\n",
    "\n",
    "### Change the number of iterations(-i) and processes (-p) in next cell. \n",
    "### Iterations should be evenly divisible by the number of processes.\n",
    "### Remember to change the ouput Directory (-o).\n",
    "\n",
    "### This step is time intensive, often overnight if using a single process.\n",
    "### Use the -p flag to increase the number of cores/processes to use for the job. \n",
    "### Be smart use fewer cores/processes than you have.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run KL test on original data, output is put in 'Kullback-Leibler' directory\n",
    "%run -i '../kullback-Leibler.py' -f 'position_weight_matrix.txt' -m '/home/mplace/projects/forMatt/Phospho_Network/forPaper/Mok_kinase_PWMs/' -i 1000 -p 4 -o '/home/mplace/projects/forMatt/Phospho_Network/forPaper/KL-shuffle/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate FDR for Each Kinase in Module using Kullback-Leiber results and write Network.SIF file.\n",
    "\n",
    "Identify FDR scores for each Mok et. al. kinase and each module by comparing\n",
    "the non-shuffled scores to the distribution of shuffled scores. The user can then manually\n",
    "define the FDR cutoff to call kinases \"motif-match\" or \"non-match\" for a given module.\n",
    "\n",
    "**Input:** Two directories and a single plain text .csv file, Kinase_Groups.csv\n",
    "provided in the git repository. \n",
    "The first directory contains plain text .csv files with KLD scores for non-shuffled Mok \n",
    "et. al. kinases and Modules. The second directory contains plain text .csv files containing\n",
    "KLD scores for shuffled Mok et. al. kinases and Modules.\n",
    "\n",
    "Csv format (For both Input Directories), **Module name is taken from file name.**\n",
    "\n",
    "|Scores|Kinase|\n",
    "|:----:|:----:|\n",
    "|13.25|cdc15|\n",
    "\n",
    "\n",
    "**Output:** A table that contains for each module, all yeast kinases, including those found in\n",
    "the Mok et. al. dataset and those that were absent, and their FDR scores for each module.\n",
    "Kinases not found in the Mok et. al. dataset are given an FDR score of 1.\n",
    "\n",
    "### Use jupyter command \"Run all below\" from this point on.  \n",
    "\n",
    "**Output:**<br>\n",
    "**Shared_interactors_Kinase_FDR.csv**  -- all yeast kinases and their FDR scores for each module, Kinases not found in the Mok et. al. dataset are given an FDR score of 1.<br>\n",
    "**Network.sif**   -- final network file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kullback-Leiber NON-Shuffled data directory\n",
    "KLDir = 'Kullback-Leibler/'\n",
    "\n",
    "# Kullback-Leiber shuffled data directory\n",
    "shufDir = 'KL-shuffle/'\n",
    "\n",
    "# Dict Kullback-Leibler NON-Shuffled values, key = Module, value = dict key = kinase, value = score\n",
    "# {'Induced_...RR.S......': {'cka1': 12.263219372654575, ....}\n",
    "kldata = {}  \n",
    "\n",
    "# Open Kullback-Leibler directory\n",
    "for file in glob.glob( 'Kullback-Leibler/' + \"*.csv\"):\n",
    "    with open(file, 'r') as f:\n",
    "        name = re.sub('.csv', '', os.path.basename(file))           # get file name from path\n",
    "        if name not in kldata:                          \n",
    "            kldata[name] = {}\n",
    "        for line in f:                                              # clean up line and split\n",
    "            line = re.sub('\\(','',line)\n",
    "            line = re.sub('\\)','',line)\n",
    "            line = re.sub('\\s+','',line)\n",
    "            line = re.sub('\\'', '', line)\n",
    "            dat = line.rstrip().split(',')\n",
    "            if dat[1] not in kldata[name]:\n",
    "                kldata[name][dat[1]] = float(dat[0])\n",
    "\n",
    "    f.close()   \n",
    "    \n",
    "# dict Kullback-Leibler shuffled data values, key = Module, value = dict key = kinase, value = list of scores\n",
    "# All scores are placed in a single list (NOT by Kinase)\n",
    "klshuf = {}\n",
    "\n",
    "for file in glob.glob(shufDir + '*.csv'):\n",
    "    with open(file, 'r') as f:\n",
    "        name = re.sub('.csv', '', os.path.basename(file))          # get file name from path\n",
    "        if name not in klshuf:                          \n",
    "            klshuf[name] = []                                      # if module not in dict add it\n",
    "        for line in f:                                             # clean up line and split\n",
    "            line = re.sub('\\(','',line)\n",
    "            line = re.sub('\\)','',line)\n",
    "            line = re.sub('\\s+','',line)\n",
    "            line = re.sub('\\'', '', line)\n",
    "            dat = line.rstrip().split(',')\n",
    "            klshuf[name].append(float(dat[0]))                      # add KL score\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "# Sort scores for module\n",
    "for k,v in klshuf.items():\n",
    "    v.sort()     \n",
    "\n",
    "# Get the total number of shuffled Kullback-Leibler trials for the False Discovery Rate calculation\n",
    "# use a random file chosen from the shuffled results directory\n",
    "with open(random.choice(glob.glob(shufDir + '*.csv')),'r') as f:\n",
    "    for trial, l in enumerate(f, 1):\n",
    "        pass\n",
    "\n",
    "# Find the position of the non-shuffled kinase score for each Module and store the value in fdr dictionary\n",
    "FDR = {}   # dict of dicts, key = Module value = dict key = kinase, value = dict { 'fdr', numScoresBelow','group'}\n",
    "\n",
    "# calculate the FDR score for each kinase in a Module\n",
    "for module, scores in kldata.items():                                # Start w/ non-shuffled data\n",
    "    for kinase in scores.keys():\n",
    "        pos = bisect.bisect_left(klshuf[module], scores[kinase] )    # returns the num of scores < original score\n",
    "        fdr = pos/trial                                              # divide pos by the total num of trials\n",
    "        if module not in FDR:                                   \n",
    "            FDR[module] = {}\n",
    "            FDR[module][kinase] = {}\n",
    "            FDR[module][kinase]['fdr'] = fdr\n",
    "            FDR[module][kinase]['numScoresBelow'] = pos\n",
    "            FDR[module][kinase]['score'] = scores[kinase]\n",
    "        else:\n",
    "            if kinase not in FDR[module]:\n",
    "                FDR[module][kinase] = {}\n",
    "            FDR[module][kinase]['fdr'] = fdr\n",
    "            FDR[module][kinase]['numScoresBelow'] = pos \n",
    "            FDR[module][kinase]['score'] = scores[kinase]\n",
    "\n",
    "# add Group (According to Mok) to the FDR dict for each Module\n",
    "# open and load required/Mok_Kinase_Groups_Corrected.csv file\n",
    "mok = {}               # dict to store Mok_Kinase_Group information\n",
    "mokName = {}           # dict maps standard name to SGD systematic name\n",
    "\n",
    "with open('required/Kinase_Groups.csv', 'r') as file:\n",
    "    file.readline()                       # skip header\n",
    "    for line in file:\n",
    "        dat = line.rstrip().split()\n",
    "        if dat[0] not in mok:             # key = kinase(yck3), value =  Acidophillic\n",
    "            mok[dat[0]] = dat[2]\n",
    "        if dat[0] not in mokName:         # key = kinase(prr1), value = YKL116C\n",
    "            mokName[dat[0]] = dat[1]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for k,v in FDR.items():                   # Go through FDR dict and add group of each kinase w/in a Module \n",
    "    for kinase,score in v.items():        # key = Induced_...RR.S......, group = 'Acidophillic'  \n",
    "        score['group'] = mok[kinase]\n",
    "        \n",
    "\n",
    "# open shared_interactors to match kinase name to Shared interactor name\n",
    "# this will include kinases 'Not_in_Mok' as well, for completeness' \n",
    "with open('Shared_interactors.csv','r') as f, open('Shared_interactors_Kinase_FDR.csv', 'w') as out:\n",
    "    header = f.readline().rstrip()\n",
    "    out.write (header + ',Kinase,Module,Group(Mok),NumScoresBelow,FDR,KLD_score\\n')\n",
    "    tmp = {}                              # dict used for sorting\n",
    "    for line in f:\n",
    "        si = line.rstrip().split(',')\n",
    "        grouping = si[0].split('_')\n",
    "        module = grouping[0] + '_' + grouping[1]\n",
    "        # if we have a kinase, keep it\n",
    "        stdName = si[9].lower()\n",
    "        print(stdName)\n",
    "        if stdName in mok:\n",
    "            if mok[stdName] == 'Not_in_Mok':\n",
    "                outline = ','.join(si) + ',' + stdName + ',' + module + ',' + 'Not_in_Mok' + ',0' + ',0' + ',0\\n'\n",
    "\n",
    "                if si[0] not in tmp:\n",
    "                    tmp[si[0]]={} \n",
    "                \n",
    "                if stdName not in tmp[si[0]]:\n",
    "                    tmp[si[0]][stdName] = { 'fdr': 0, 'data': outline }\n",
    "            else:\n",
    "                outline = ','.join(si) + ',' + stdName + ',' + module + ',' + FDR[module][stdName]['group'] +\\\n",
    "                ',' + str(FDR[module][stdName]['numScoresBelow']) +  ',' + str(FDR[module][stdName]['fdr']) +\\\n",
    "                ',' + str(FDR[module][stdName]['score']) + '\\n' \n",
    "\n",
    "                if si[0] not in tmp:\n",
    "                    tmp[si[0]]={} \n",
    "                \n",
    "                if stdName not in tmp[si[0]]:\n",
    "                    tmp[si[0]][stdName] = { 'fdr': FDR[module][stdName]['fdr'], 'data': outline }\n",
    "\n",
    "    # sort each subModule group by the FDR and write to file\n",
    "    for m in tmp.keys():                             \n",
    "        fdrOrd = sorted(tmp[m].items(), key=lambda k_v: k_v[1]['fdr'])\n",
    "        for i in fdrOrd:\n",
    "            out.write((i[1]['data']))           \n",
    "        \n",
    "out.close()\n",
    "f.close()\n",
    "\n",
    "\n",
    "# load kinase & phosphatase annotation\n",
    "annotation = {}                                        # key = ORF name, value = annotation( Kinase or Phosphatase)\n",
    "with open('required/kinase_phosphatase_yeast.csv', 'r') as f:\n",
    "    f.readline()                                                # skip header\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        if dat[0] not in annotation:\n",
    "            annotation[dat[0]] = dat[1]\n",
    "f.close()\n",
    "\n",
    "# Open Submodules.txt, Shared_interactors.csv to create the final Network SIF file\n",
    "\n",
    "outFile = open('Network.sif', 'w')                              # open output file\n",
    "header = ['Interactor_A', 'Edge_Type', 'Interactor_B', 'Annotation' '\\n']    # header column names\n",
    "outFile.write('\\t'.join(header))\n",
    "\n",
    "with open('Submodules.txt', 'r') as f:\n",
    "    f.readline()                                               # skip header\n",
    "    for sub in f:\n",
    "        line = sub.rstrip().split(',')\n",
    "        if line[1] in annotation:\n",
    "            line.append(annotation[line[1]])\n",
    "        else:\n",
    "            line.append('\\t')\n",
    "        line.insert(1,'Constituent')\n",
    "        outFile.write('\\t'.join(line))\n",
    "        outFile.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# find the max difference between the ordered FDR values within a submodule\n",
    "# dict, key = subModule Name, value = { 'fdr': list of fdr scores,  'data': list of original row data }\n",
    "cutoff = {}   \n",
    "track  = {}  # dictionary to keep track of Shared_interactors printed which are kinases, so we don't double print\n",
    "\n",
    "with open('Shared_interactors_Kinase_FDR.csv', 'r') as f:\n",
    "    f.readline()                                                 # skip header\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        \n",
    "        if dat[0] not in cutoff:\n",
    "            cutoff[dat[0]] = { 'fdr' : [], 'data' : [] }\n",
    "            \n",
    "        cutoff[dat[0]]['fdr'].append(dat[-2])                    # get FDR score\n",
    "        cutoff[dat[0]]['data'].append(line.rstrip())             # get original line from file\n",
    "f.close()\n",
    "\n",
    "maxDif = -10     # maximum difference between steps in fdr list\n",
    "index  = -1      # index of list, 1 to index will be output in final sif\n",
    "\n",
    "for k,v in cutoff.items():\n",
    "    for i in range(len(v['fdr']) - 1):\n",
    "        dif = math.fabs(float(v['fdr'][i]) - float(v['fdr'][i+1]))      \n",
    "        #print(i, i+1,v['fdr'][i] ,v['fdr'][i+1], dif) \n",
    "        if dif > maxDif:                                         # set index and difference\n",
    "            maxDif = dif\n",
    "            index = i + 1\n",
    "    #print(maxDif, index)\n",
    "    for x in range(len(v['fdr'])):                               # Not set the specificity for kinases\n",
    "        row = v['data'][x].split(',')\n",
    "        if row[0] not in track:\n",
    "            track[row[0]] = set()\n",
    "            track[row[0]].add(row[1])\n",
    "        else:\n",
    "            track[row[0]].add(row[1])\n",
    "        \n",
    "        if row[13] == 'Not_in_Mok':\n",
    "            specificity = 'Unknown Specificity Match'\n",
    "        else:\n",
    "            if x < index:                                        # if < cutoff (maxDif)\n",
    "                specificity = 'Motif Match'\n",
    "            else:\n",
    "                specificity = 'Unmatched Specificity'\n",
    "                \n",
    "        if row[9] == 'output' or row[9] == 'None':\n",
    "            outFile.write('%s,%s,%s,%s\\n' %(row[0], specificity, row[1], 'kinase'))\n",
    "        else:\n",
    "            outFile.write('%s,%s,%s,%s\\n' %(row[1], specificity, row[0], 'kinase'))\n",
    "            \n",
    "    \n",
    "    # reset for next subModule\n",
    "    maxDif = -10\n",
    "    index = -1\n",
    "\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outFile = open('Network.sif', 'a')\n",
    "                \n",
    "# open Shared_interactors.csv and add Shared interactors that are not kinases\n",
    "with open('Shared_interactors.csv', 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        dat = line.rstrip().split(',')\n",
    "        if dat[0] not in track:\n",
    "            if dat[9] == 'output' or dat[9] == 'None':\n",
    "                outFile.write('%s,%s,%s\\n' %(dat[0], 'Shared Interactor', dat[1]))\n",
    "            else:\n",
    "                outFile.write('%s,%s,%s\\n' %(dat[1], 'Shared Interactor', dat[0]))            \n",
    "        else:\n",
    "            if dat[1] not in track[dat[0]]:\n",
    "                if dat[9] == 'output' or dat[9] == 'None':\n",
    "                    outFile.write('%s,%s,%s\\n' %(dat[0], 'Shared Interactor', dat[1]))\n",
    "                else:\n",
    "                    outFile.write('%s,%s,%s\\n' %(dat[1], 'Shared Interactor', dat[0]))\n",
    "f.close()\n",
    "outFile.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
